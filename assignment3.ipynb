{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Classification with Logistic Regression\n",
    "\n",
    "# Total: /100\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Complete the assignment\n",
    "\n",
    "* Once the notebook is complete, restart your kernel and rerun your cells\n",
    "\n",
    "* Submit this notebook to owl by the deadline\n",
    "\n",
    "* You may use any python library functions you wish to complete the assignment.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders. \n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \\[You will learn about PCA in a later Lesson.\\] Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "You can read more about the data and the variables [here](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need these\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: /5 pts\n",
    "\n",
    "Read in the `creditcard.csv` dataset and display the first 5 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: /5 pts\n",
    "\n",
    "Then split the data into train and test for the outcome/response and the predictor variables. Hold out 50% of observations as the test set.  Pass `random_state=0` to `train_test_split` to ensure you get the same train and tests sets as the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 code here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: /5 pts\n",
    "\n",
    "Read the documentation for [sklearn's `LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).  In no more than 2 sentences per bullet point, answer the following in your own words.\n",
    "\n",
    "* Does `LogisticRegression` use a penalty by default?  If yes, what penalty?\n",
    "\n",
    "**YOUR ANSWER HERE:** \n",
    "    \n",
    "* If we apply a penalty during learning, what difference do you expect to see in the resulting coefficients, relative to not applying a penalty during learning?\n",
    "\n",
    "**YOUR ANSWER HERE:** \n",
    "    \n",
    "* If using the default settings of `LogisticRegression` in `sklearn`, should you include a column of 1s in your feature/design matrix? Briefly explain why or why not.\n",
    "\n",
    "**YOUR ANSWER HERE:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: /15 pts\n",
    "\n",
    "Create a instance of sklearn's `LogisticRegression` object for unpenalized logistic regression. Note: If you get a warning about convergence of `coef_`, try increasing the `max_iter` parameter.  I used `max_iter=10000` which seems to supress the warning.\n",
    "\n",
    "Using this object, **run a logisitic regression analysis** of `Class` (y-variable) against `Amount` (x-variable) using your training data. \n",
    "\n",
    "Then **make a plot with three main components based on the analysis**:\n",
    "1. Scatter-plot of `Amount` and `Outcome` on your test data\n",
    "2. A curve showing the prediction (0 or 1, using `predict` - this curve will jump between 0 and 1) as a function of `Amount`\n",
    "3. A curve showing the predicted probability of a positive outcome (using `predict_proba`) as a function of `Amount`. Note that `predict_proba` will return both p(Outcome=0) and p(Outcome=1) in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: 15 pts\n",
    "\n",
    "Compute the label-based criteria we discussed in the Lesson for your amount-only classifier **using the test data**. Use a threshold of 0.5. Answer the questions in this text box below.\n",
    "\n",
    "* How many of the test instances are labeled positive by your classifier?\n",
    "\n",
    "**YOUR ANSWER HERE:** \n",
    "\n",
    "* Choose one of the positively-labeled test instances, and explain why the classifier labeled it positive.\n",
    "\n",
    "**YOUR ANSWER HERE:** \n",
    "\n",
    "* Is this classifier useful for finding fraudulent transactions? Explain in one or two sentences.\n",
    "\n",
    "**YOUR ANSWER HERE:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance measures from scratch\n",
    "# TP: true postives \n",
    "# TN: true negatives \n",
    "# FP: False positives \n",
    "# FN: False negatives\n",
    "def compute_performance(yhat, y, classes):\n",
    "    # First, get tp, tn, fp, fn\n",
    "    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n",
    "    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n",
    "    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n",
    "    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n",
    "\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision\n",
    "    # \"Of the ones I labeled +, how many are actually +?\"\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    # Recall\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    recall = tp / (tp + fn)    \n",
    "    \n",
    "    # Sensitivity\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    sensitivity = recall\n",
    "    \n",
    "    # Specificity\n",
    "    # \"Of all the - in the data, how many do I correctly label?\"\n",
    "    specificity = tn / (fp + tn)\n",
    "    \n",
    "    # Print results\n",
    "    \n",
    "    print(\"Accuracy:\",round(acc,3),\"Recall:\",round(recall,3),\"Precision:\",round(precision,3),\n",
    "          \"Sensitivity:\",round(sensitivity,3),\"Specificity:\",round(specificity,3))\n",
    "\n",
    "## Put code here to compute criteria:\n",
    "    \n",
    "\n",
    "## Put code here to compute whatever else you might need to answer the question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: /10 pts\n",
    "Now fit a logistic regression model to the training data and include all the variables in the data frame (except for `Class`) in the cell below. You will want to make a new object like you did for the simpler model. Answer the following question.\n",
    "\n",
    "* According to this more complex model, are larger or smaller Amounts more strongly associated with fraud, if all other variables are held equal?\n",
    "\n",
    "**YOUR ANSWER HERE:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Question 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: /15 pts\n",
    "\n",
    "In the cell below, Compute the label-based criteria we discussed in the Lesson for new classifier using the test data. (You don't have to copy the function down into this cell; just call it again here.) Use a threshold of 0.5. Answer the questions in this text box below.\n",
    "\n",
    "* How many of the test instances are labeled positive by your classifier?\n",
    "\n",
    "**YOUR ANSWER:** \n",
    "\n",
    "* Is this classifier **better or worse than the amount-only classifier** for finding fraudulent transactions? Explain in one or two sentences.*\n",
    "\n",
    "**YOUR ANSWER:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Question 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8: /15 pts\n",
    "\n",
    "Plot ROC curves for both of your classifiers using the cells below, then answer the following questions, computing whatever quantities you need to answer them.\n",
    "\n",
    "* Which classifier has a higher estimated probability of correctly distinguishing between a positive and a negative instance? How do you know?\n",
    "\n",
    "**YOUR ANSWER:** \n",
    "\n",
    "* How could you explain a result where a logistic regression classifier produces an AUROC that is \"worse than random\", i.e. less than 0.5, even on its training set?\n",
    "\n",
    "**YOUR ANSWER:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for Amount-only classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for all-variable classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9: /15 pts\n",
    "\n",
    "Plot precision-recall curves for both of your classifiers using the cell below. Be sure to label your axes.\n",
    "\n",
    "* Which classifier is preferable if we want to recover at least 60% of fraudulent transactions?\n",
    "\n",
    "**YOUR ANSWER:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRC for Amount-only classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRC for all-variable classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}